{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "train_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def plot_bboxes(df: pd.DataFrame, upd_path=True):\n",
    "    for _, row in df.iterrows():\n",
    "        img = io.imread(('data/bear_images/bear_images/' if upd_path else '') + row['file_name'])\n",
    "        cv2.rectangle(img, (row['x1'], row['y1']), (row['x2'], row['y2']), (255, 0, 0), 5)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(img, str(row['confidence']), (row['x1'], row['y1'] - 10), font, 1, (0, 255, 0),\n",
    "                    5)\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.title(row['file_name'])\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_bboxes(train_df[train_df.confidence == 1.0][:5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_bboxes(sample_submission[sample_submission.confidence > 0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Solution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from skimage import io\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torchvision\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import datetime as dt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "NUM_WORKERS = 4\n",
    "NUM_EPOCH = 50"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(SEED)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class BearDataset(Dataset):\n",
    "    def __init__(self, root_dir: str, csv_path, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        df = pd.read_csv(csv_path)\n",
    "        self.files = list(df[\"file_name\"].map(lambda p: os.path.join(root_dir, p)))\n",
    "        self.targets = df.drop(columns=['file_name'])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = io.imread(self.files[index])\n",
    "        img = img[:, :, :3]\n",
    "        target = self.targets.iloc[index, :]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        is_bear = target['confidence'] > 0\n",
    "        boxes = [target[\"x1\"], target[\"y1\"], target[\"x2\"] if is_bear else img.shape[2], target[\"y2\"] if is_bear else img.shape[1]]\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        return img, {\"boxes\": boxes, \"labels\": torch.as_tensor(1 if is_bear else 0, dtype=torch.int64),\n",
    "                     \"scores\": torch.as_tensor(1, dtype=torch.float32)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class BearTestDataset(Dataset):\n",
    "    def __init__(self, root_dir: str, csv_path, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        df = pd.read_csv(csv_path)\n",
    "        self.files = list(df[\"file_name\"].map(lambda p: os.path.join(root_dir, p)))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = io.imread(self.files[index])\n",
    "        img = img[:, :, :3]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, {}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = [\n",
    "        T.ToTensor()\n",
    "    ]\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "dataset_train_raw = BearDataset('./data/bear_images/bear_images', './data/train.csv',\n",
    "                                get_transform(train=True))\n",
    "dataset_test_raw = BearDataset('./data/bear_images/bear_images', './data/train.csv',\n",
    "                               get_transform(train=False))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "labels = [c > 0 for c in dataset_train_raw.targets.confidence]\n",
    "indices = list(range(len(dataset_train_raw)))\n",
    "ind_train, ind_test, _, _ = train_test_split(indices, labels, test_size=0.2, random_state=SEED,\n",
    "                                             stratify=labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "dataset_train = torch.utils.data.Subset(dataset_train_raw, ind_train)\n",
    "dataset_test = torch.utils.data.Subset(dataset_test_raw, ind_test)\n",
    "\n",
    "data_loader_train = DataLoader(\n",
    "    dataset_train, shuffle=True, num_workers=NUM_WORKERS)\n",
    "\n",
    "data_loader_test = DataLoader(\n",
    "    dataset_test, shuffle=False, num_workers=NUM_WORKERS)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eugen/coding/find_a_bear/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/eugen/coding/find_a_bear/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = get_model()\n",
    "\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.001,\n",
    "                            momentum=0.9, weight_decay=0.0005)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                                   step_size=1,\n",
    "                                                   gamma=0.1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "!export PYTORCH_CUDA_ALLOC_CONF=garbage_collection_threshold:0.7"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def sanitize_pred(yhat_i):\n",
    "    if yhat_i['scores'].dim() > 0 and len(yhat_i['scores']) == 0:\n",
    "        yhat_i['scores'] = torch.as_tensor([0], dtype=torch.float32)\n",
    "        yhat_i['boxes'] = torch.as_tensor([[0, 0, 0, 0]], dtype=torch.float32)\n",
    "        yhat_i['labels'] = torch.as_tensor([0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def mcrmse(yhat, y):\n",
    "    sanitize_pred(yhat[0])\n",
    "\n",
    "    best_box_idx = max(range(len(yhat[0]['scores'])), key=lambda i: yhat[0]['scores'][i])\n",
    "    score = 0\n",
    "    for i in range(4):\n",
    "        score += mean_squared_error([yhat[0]['boxes'][best_box_idx].cpu()[i] if yhat[0]['labels'].cpu()[best_box_idx] == 1 else 0], [y[0]['boxes'].cpu()[0][i] if y[0]['labels'].cpu().item() == 1 else 0],\n",
    "                                    squared=False)\n",
    "\n",
    "    return score / 4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "best_score = None\n",
    "best_model = None"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "for i in range(NUM_EPOCH):\n",
    "    train_losses_batch = []\n",
    "    test_losses_batch = []\n",
    "\n",
    "    model.train()\n",
    "    for images, targets in tqdm(data_loader_train, desc='train'):\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in [targets]]\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses_batch.append(losses.item())\n",
    "\n",
    "    # lr_scheduler.step()\n",
    "    model.eval()\n",
    "    for images, targets in tqdm(data_loader_test, desc='test'):\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in [targets]]\n",
    "        with torch.set_grad_enabled(False):\n",
    "            output = model(images)\n",
    "            loss = mcrmse(output, targets)\n",
    "            test_losses_batch.append(loss)\n",
    "\n",
    "    train_loss = np.mean(train_losses_batch)\n",
    "    test_loss = np.mean(test_losses_batch)\n",
    "\n",
    "    if best_score is None or test_loss < best_score:\n",
    "        best_score = test_loss\n",
    "        best_model = deepcopy(model)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    print(f'Epoch {i + 1}/{NUM_EPOCH}\\t{train_loss=}\\t{test_loss=}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.272993592654958\n"
     ]
    }
   ],
   "source": [
    "print(best_score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "torch.save(best_model.state_dict(), f'weights/model_{dt.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.pt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def pred_to_df(yhat, file_names, use_best=False):\n",
    "    def get_best_idx(yhat_i):\n",
    "        return max(range(len(yhat_i['scores'].cpu())), key=lambda j: yhat_i['scores'].cpu()[j])\n",
    "\n",
    "    def get_p(idx):\n",
    "        pts = []\n",
    "        for yhat_i in yhat:\n",
    "            if use_best:\n",
    "                best_idx = get_best_idx(yhat_i)\n",
    "                if yhat_i['labels'][best_idx] != 1:\n",
    "                    pt = 0\n",
    "                else:\n",
    "                    pt = yhat_i['boxes'].cpu()[best_idx][idx]\n",
    "            else:\n",
    "                pt = yhat_i['boxes'].cpu()[idx]\n",
    "            pts.append(pt)\n",
    "        return np.array(pts, dtype=np.int64)\n",
    "\n",
    "    [sanitize_pred(yi) for yi in yhat]\n",
    "    df = pd.DataFrame(columns=train_df.columns)\n",
    "    df['file_name'] = file_names\n",
    "    df['x1'] = get_p(0)\n",
    "    df['y1'] = get_p(1)\n",
    "    df['x2'] = get_p(2)\n",
    "    df['y2'] = get_p(3)\n",
    "    df['confidence'] = [1.0 * (yi['labels'].cpu()[get_best_idx(yi)].item() if use_best else yi['labels'].cpu().item()) for yi in yhat]\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result = pred_to_df([dataset_test_raw[0][1]], [dataset_test_raw.files[0]])\n",
    "plot_bboxes(result, False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[[0.3216, 0.3255, 0.3255,  ..., 0.1529, 0.1490, 0.1216],\n          [0.3255, 0.3255, 0.3255,  ..., 0.1686, 0.1608, 0.1373],\n          [0.3294, 0.3294, 0.3294,  ..., 0.1804, 0.1608, 0.1412],\n          ...,\n          [0.7333, 0.7333, 0.7333,  ..., 0.6000, 0.6000, 0.5961],\n          [0.7333, 0.7333, 0.7333,  ..., 0.6000, 0.5961, 0.5922],\n          [0.7333, 0.7333, 0.7373,  ..., 0.5961, 0.5922, 0.5922]],\n \n         [[0.3373, 0.3412, 0.3451,  ..., 0.0941, 0.0980, 0.0784],\n          [0.3373, 0.3412, 0.3451,  ..., 0.1059, 0.1059, 0.0863],\n          [0.3412, 0.3412, 0.3412,  ..., 0.1176, 0.1020, 0.0863],\n          ...,\n          [0.8039, 0.8039, 0.8039,  ..., 0.6667, 0.6667, 0.6627],\n          [0.8039, 0.8039, 0.8039,  ..., 0.6706, 0.6667, 0.6627],\n          [0.8039, 0.8039, 0.8078,  ..., 0.6667, 0.6627, 0.6627]],\n \n         [[0.3373, 0.3373, 0.3373,  ..., 0.1059, 0.1020, 0.0745],\n          [0.3373, 0.3373, 0.3373,  ..., 0.1137, 0.1059, 0.0784],\n          [0.3412, 0.3373, 0.3373,  ..., 0.1098, 0.0902, 0.0745],\n          ...,\n          [0.8863, 0.8863, 0.8902,  ..., 0.7608, 0.7608, 0.7569],\n          [0.8863, 0.8863, 0.8863,  ..., 0.7608, 0.7569, 0.7529],\n          [0.8863, 0.8863, 0.8902,  ..., 0.7569, 0.7529, 0.7529]]]),\n {'boxes': tensor([ 83., 129., 566., 825.]),\n  'labels': tensor(1),\n  'scores': tensor(1.)})"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from random import randint\n",
    "with torch.set_grad_enabled(False):\n",
    "    idx = randint(0, len(dataset_test_raw))\n",
    "    pred = model([dataset_test_raw[idx][0].to(device)])\n",
    "    result_pred = pred_to_df(pred, [dataset_test_raw.files[idx]], use_best=True)\n",
    "    plot_bboxes(pred_to_df([dataset_test_raw[idx][1]], [dataset_test_raw.files[idx]]), False)\n",
    "    plot_bboxes(result_pred, False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./weights/model_20230319_154804.pt'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "test_data = BearTestDataset('data/bear_images/bear_images', 'data/test.csv', get_transform(False))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "model.eval()\n",
    "with torch.set_grad_enabled(False):\n",
    "    idx = randint(0, len(test_data))\n",
    "    pred = model([test_data[idx][0].to(device)])\n",
    "    result_pred = pred_to_df(pred, [test_data.files[idx]], use_best=True)\n",
    "    plot_bboxes(result_pred, False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 149/149 [00:23<00:00,  6.26it/s]\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "for img, _ in tqdm(test_data):\n",
    "    with torch.set_grad_enabled(False):\n",
    "        pred = best_model([img.to(device)])\n",
    "        y_pred.append(pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "submission = pred_to_df(sum(y_pred, []), test_data.files, True)\n",
    "submission.file_name = submission.file_name.apply(lambda p: os.path.basename(p))\n",
    "submission.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "submission.to_csv(f'./data/submission_{dt.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_bboxes(submission[submission.confidence == 0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Blend"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "sus_images = ['image_116.jpeg', 'image_166.jpeg', 'image_170.png', 'image_346.jpeg', 'image_348.jpeg', 'image_375.png', 'image_391.jpeg', 'image_396.jpeg', 'image_437.jpeg', 'image_485.jpeg']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "best_submission = pd.read_csv('data/submission_20230319_004813.csv')\n",
    "prev_submission = pd.read_csv('data/submission_20230319_154945.csv')\n",
    "last_submission = pd.read_csv('data/submission_20230319_155311.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_submission[best_submission.file_name.isin(sus_images)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_bboxes(best_submission[best_submission.file_name.isin(sus_images)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_bboxes(prev_submission[prev_submission.file_name.isin(sus_images)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "blended = last_submission.set_index('file_name')\n",
    "blended.update(prev_submission[prev_submission.file_name.isin(sus_images) & prev_submission.confidence > 0].set_index('file_name'))\n",
    "blended.update(best_submission[best_submission.file_name.isin(sus_images) & best_submission.confidence > 0].set_index('file_name'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "blended = blended.reset_index()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "blended[['x1', 'y1', 'x2', 'y2']] = blended[['x1', 'y1', 'x2', 'y2']].astype(np.int64)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "blended.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_bboxes(blended[blended.file_name.isin(sus_images)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "import datetime as dt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "blended.to_csv(f'./data/submission_{dt.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Blend 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "best_submission = pd.read_csv('data/submission_20230319_173121.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_bboxes(best_submission[best_submission.confidence == 1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "images = ['image_292.png', 'image_286.png', 'image_235.png', 'image_224.png', 'image_218.png', 'image_179.jpeg', 'image_166.jpeg']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import os"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for submission in filter(lambda p: p.startswith('submission'), os.listdir('data')):\n",
    "    print(submission)\n",
    "    df = pd.read_csv('data/' + submission)\n",
    "    plot_bboxes(df[df['file_name'].isin(images[4:])])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "to_replace = {\n",
    "    'image_286.png': 'submission_20230319_004813.csv',\n",
    "    'image_235.png': 'submission_20230319_154945.csv',\n",
    "    'image_224.png': 'submission_20230319_154945.csv',\n",
    "    'image_179.jpeg': 'submission_20230319_154945.csv',\n",
    "    'image_218.png': 'submission_20230319_004813.csv',\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "blended = best_submission.set_index('file_name')\n",
    "for img, take_from in to_replace.items():\n",
    "    other = pd.read_csv('data/' + take_from)\n",
    "    blended.update(other[other.file_name == img].set_index('file_name'))\n",
    "\n",
    "blended = blended.reset_index()\n",
    "blended.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "blended[['x1', 'y1', 'x2', 'y2']] = blended[['x1', 'y1', 'x2', 'y2']].astype(np.int64)\n",
    "blended.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_bboxes(blended[blended.confidence == 1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "blended.to_csv(f'./data/submission_{dt.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
